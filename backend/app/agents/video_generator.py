from __future__ import annotations

from sqlalchemy import select

from app.agents.base import AgentContext, BaseAgent
from app.agents.utils import build_character_context
from app.models.project import Character, Shot
from app.services.doubao_video import DoubaoVideoService
from app.services.image_composer import ImageComposer


class VideoGeneratorAgent(BaseAgent):
    """ä¸ºåˆ†é•œç”Ÿæˆè§†é¢‘"""
    name = "video_generator"

    def __init__(self):
        super().__init__()
        self.image_composer = ImageComposer()

    def _build_video_prompt(self, shot: Shot, characters: list[Character], *, style: str) -> str:
        """æ„å»ºè§†é¢‘ç”Ÿæˆ prompt"""
        # ä¼˜å…ˆä½¿ç”¨ promptï¼ˆç”± Scriptwriter ç”Ÿæˆçš„ video_promptï¼‰
        desc = shot.prompt or shot.description
        parts = [desc.strip()]

        # ä½¿ç”¨å·¥å…·å‡½æ•°æ„å»ºè§’è‰²ä¸Šä¸‹æ–‡
        char_context = build_character_context(characters)
        if char_context:
            parts.append(char_context)

        if style.strip():
            parts.append(f"Style: {style.strip()}")

        return ", ".join(parts)

    def _get_duration(self, shot: Shot, default_duration: float) -> float:
        """è·å–è§†é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰"""
        if shot.duration and shot.duration > 0:
            return shot.duration
        return default_duration

    async def run(self, ctx: AgentContext) -> None:
        # ä½¿ç”¨åŸºç±»æ–¹æ³•æŸ¥è¯¢é¡¹ç›®è§’è‰²
        characters = await self.get_project_characters(ctx)

        # æŸ¥æ‰¾æ²¡æœ‰è§†é¢‘çš„ Shotï¼ˆå¯æŒ‰ç›®æ ‡åˆ†é•œè¿‡æ»¤ï¼‰
        query = (
            select(Shot)
            .where(
                Shot.project_id == ctx.project.id,
                Shot.video_url.is_(None),
            )
        )
        if ctx.target_ids and ctx.target_ids.shot_ids:
            query = query.where(Shot.id.in_(ctx.target_ids.shot_ids))
        res = await ctx.session.execute(query)
        shots = res.scalars().all()
        if not shots:
            await self.send_message(ctx, "æ‰€æœ‰åˆ†é•œå·²æœ‰è§†é¢‘ã€‚")
            return

        # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨å›¾ç”Ÿè§†é¢‘æ¨¡å¼
        use_image_mode = ctx.settings.use_i2v()
        # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨è±†åŒ…æœåŠ¡
        is_doubao = isinstance(ctx.video, DoubaoVideoService)
        default_duration = (
            float(ctx.settings.doubao_video_duration) if is_doubao else 5.0
        )

        total = len(shots)
        updated_count = 0

        mode_desc = "å›¾ç”Ÿè§†é¢‘" if use_image_mode else "æ–‡ç”Ÿè§†é¢‘"
        provider_desc = "è±†åŒ…" if is_doubao else "OpenAIå…¼å®¹"
        image_mode = (ctx.settings.video_image_mode or "first_frame").strip().lower()
        # å‘é€å¸¦è¿›åº¦çš„æ¶ˆæ¯
        await self.send_message(
            ctx,
            f"ğŸ¬ å¼€å§‹ä¸º {total} ä¸ªåˆ†é•œç”Ÿæˆè§†é¢‘ï¼ˆ{mode_desc}ï¼‰...",
            progress=0.0,
            is_loading=True
        )

        for i, shot in enumerate(shots):
            try:
                # ä½¿ç”¨åŸºç±»æ–¹æ³•å‘é€è¿›åº¦æ¶ˆæ¯
                await self.send_progress_batch(
                    ctx,
                    total=total,
                    current=i,
                    message=f"   æ­£åœ¨ç”Ÿæˆè§†é¢‘ {i+1}/{total}...",
                )

                video_prompt = self._build_video_prompt(shot, characters, style=ctx.project.style)
                duration = self._get_duration(shot, default_duration)

                # æ ¹æ®æœåŠ¡ç±»å‹é€‰æ‹©ä¸åŒçš„è°ƒç”¨æ–¹å¼
                if is_doubao:
                    # è±†åŒ…æœåŠ¡ï¼šä½¿ç”¨å›¾ç‰‡ URL
                    image_url: str | None = None
                    if use_image_mode and shot.image_url:
                        if image_mode == "reference":
                            try:
                                # æ”¶é›†æœ‰å›¾ç‰‡çš„è§’è‰²
                                char_image_urls = [c.image_url for c in characters if c.image_url]

                                # æ‹¼æ¥åˆ†é•œå›¾å’Œè§’è‰²å›¾ï¼Œä¿å­˜åˆ°æœ¬åœ°å¹¶è·å– URL
                                image_url = await self.image_composer.compose_and_save_reference_image(
                                    shot_image_url=shot.image_url,
                                    character_image_urls=char_image_urls,
                                )
                                await self.send_message(
                                    ctx,
                                    f"é•œå¤´ {shot.order}: å·²ç”Ÿæˆå‚è€ƒå›¾ï¼ˆåˆ†é•œå›¾ + {len(char_image_urls)} ä¸ªè§’è‰²å›¾ï¼‰",
                                )
                            except Exception as e:
                                await self.send_message(
                                    ctx,
                                    f"é•œå¤´ {shot.order}: å‚è€ƒå›¾ç”Ÿæˆå¤±è´¥ï¼Œå°†ä½¿ç”¨åˆ†é•œé¦–å¸§å›¾: {e}",
                                )
                                image_url = shot.image_url
                        else:
                            image_url = shot.image_url

                    # è±†åŒ…æœåŠ¡çš„ generate_url æ¥å£
                    video_url = await ctx.video.generate_url(
                        prompt=video_prompt,
                        image_url=image_url,
                        duration=int(duration) if duration in (5, 10) else 5,
                        ratio=ctx.settings.doubao_video_ratio,
                        generate_audio=ctx.settings.doubao_generate_audio,
                    )
                else:
                    # OpenAI å…¼å®¹æœåŠ¡ï¼šä½¿ç”¨å›¾ç‰‡å­—èŠ‚æµ
                    reference_image_bytes: bytes | None = None
                    if use_image_mode and shot.image_url:
                        try:
                            if image_mode == "reference":
                                # æ”¶é›†æœ‰å›¾ç‰‡çš„è§’è‰²
                                char_image_urls = [c.image_url for c in characters if c.image_url]

                                # æ‹¼æ¥åˆ†é•œå›¾å’Œè§’è‰²å›¾
                                reference_image_bytes = await self.image_composer.compose_reference_image(
                                    shot_image_url=shot.image_url,
                                    character_image_urls=char_image_urls,
                                )
                                await self.send_message(ctx, f"é•œå¤´ {shot.order}: å·²ç”Ÿæˆå‚è€ƒå›¾ï¼ˆåˆ†é•œå›¾ + {len(char_image_urls)} ä¸ªè§’è‰²å›¾ï¼‰")
                            else:
                                # ä»…ä½¿ç”¨åˆ†é•œé¦–å¸§å›¾
                                reference_image_bytes = await self.image_composer.compose_reference_image(
                                    shot_image_url=shot.image_url,
                                    character_image_urls=[],
                                )
                        except Exception as e:
                            await self.send_message(ctx, f"é•œå¤´ {shot.order}: å‚è€ƒå›¾ç”Ÿæˆå¤±è´¥ï¼Œå°†ä½¿ç”¨æ–‡ç”Ÿè§†é¢‘æ¨¡å¼: {e}")
                            reference_image_bytes = None

                    # OpenAI å…¼å®¹æœåŠ¡çš„ generate_url æ¥å£
                    video_url = await ctx.video.generate_url(
                        prompt=video_prompt,
                        image_bytes=reference_image_bytes,
                    )

                shot.video_url = video_url
                shot.duration = duration  # ç¡®ä¿æ—¶é•¿è¢«è®°å½•
                ctx.session.add(shot)
                await ctx.session.flush()  # ç¡®ä¿æ›´æ–°ç”Ÿæ•ˆ
                # å‘é€åˆ†é•œæ›´æ–°äº‹ä»¶
                await self.send_shot_event(ctx, shot, "shot_updated")
                updated_count += 1
            except Exception as e:
                await self.send_message(ctx, f"é•œå¤´ {shot.order} è§†é¢‘ç”Ÿæˆå¤±è´¥: {e}")

        await ctx.session.commit()
        # å®Œæˆæ¶ˆæ¯
        if updated_count > 0:
            await self.send_message(ctx, f"âœ… å·²ä¸º {updated_count} ä¸ªåˆ†é•œç”Ÿæˆè§†é¢‘ï¼Œæ¥ä¸‹æ¥å°†åˆæˆå®Œæ•´è§†é¢‘ã€‚", progress=1.0, is_loading=False)
        else:
            await self.send_message(ctx, f"âŒ æ‰€æœ‰åˆ†é•œè§†é¢‘ç”Ÿæˆå‡å¤±è´¥ã€‚", progress=1.0, is_loading=False)
